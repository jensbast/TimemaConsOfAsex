{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### script to extract ortholog variants"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### INIT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import copy\n",
    "import os\n",
    "from os.path import isfile, join, isdir\n",
    "\n",
    "og_file = \"./Output/OrthologousGroups.txt\"\n",
    "mapping_file = \"./Output/Map-SeqNum-ID.txt\"\n",
    "PR_folder = \"./Output/PairwiseOrthologs/\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Do mapping oma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Map_species_id(object):\n",
    "\t'''\n",
    "\tObject to map species and genes from the Map-SeqNum-ID.txt in the OMA standalone Output folder.\n",
    "\t--| SPECIES  int_id  ext_id |--\n",
    "\t'''\n",
    "\n",
    "\tdef create_map(self, _inputfile):\n",
    "\t\tmap_dict = {}\n",
    "\n",
    "\t\tdata = np.genfromtxt(_inputfile, dtype=None , delimiter=\"\\t\", usecols=(0,1,2))\n",
    "\t\tfor line in data:\n",
    "\t\t\tmap_dict.setdefault(line[0],[]).append([line[1],line[2]])\n",
    "\t\treturn map_dict\n",
    "\n",
    "\tdef __init__(self, _inputfile):\n",
    "\t\tself.map = self.create_map(_inputfile)\n",
    "\n",
    "\tdef get_extid(self,query_id, query_species):\n",
    "\t\t'''\n",
    "\t\treturn external id using species + internal id\n",
    "\t\t:param query_id:\n",
    "\t\t:param query_species:\n",
    "\t\t:return:\n",
    "\t\t'''\n",
    "\t\tfor species,entries in self.map.iteritems():\n",
    "\t\t\tif query_species == species:\n",
    "\t\t\t\tfor entry in entries:\n",
    "\t\t\t\t\tif entry[0] == int(query_id):\n",
    "\t\t\t\t\t\treturn entry[1]\n",
    "\n",
    "\tdef get_omaid(self,query_id, query_species):\n",
    "\t\t'''\n",
    "\t\treturn internal id using species + external id\n",
    "\t\t:param query_omaid:\n",
    "\t\t:param query_species:\n",
    "\t\t:return:\n",
    "\t\t'''\n",
    "\t\tfor species,entries in self.map.iteritems():\n",
    "\t\t\tif query_species == species:\n",
    "\t\t\t\tfor entry in entries:\n",
    "\t\t\t\t\tif entry[1] == query_id:\n",
    "\t\t\t\t\t\treturn entry[0]\n",
    "\n",
    "\tdef get_species_with_ext(self,query_extid):\n",
    "\t\t'''\n",
    "\t\tget the species related to an external id\n",
    "\t\t:param query_extid:\n",
    "\t\t:return:\n",
    "\t\t'''\n",
    "\t\tfor species,entries in self.map.iteritems():\n",
    "\t\t\t\tfor entry in entries:\n",
    "\t\t\t\t\tif query_extid == entry[1]:\n",
    "\t\t\t\t\t\treturn species\n",
    "\n",
    "\tdef get_species_with_int(self,query_intid):\n",
    "\t\t'''\n",
    "\t\tget the species related to an internal id\n",
    "\t\t:param query_intid:\n",
    "\t\t:return:\n",
    "\t\t'''\n",
    "\t\tfor species,entries in self.map.iteritems():\n",
    "\t\t\t\tfor entry in entries:\n",
    "\t\t\t\t\tif query_intid == entry[0]:\n",
    "\t\t\t\t\t\treturn species\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "map_id = Map_species_id(mapping_file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Read OG file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "100 OGs computed/ 13396\n",
      "200 OGs computed/ 13396\n",
      "300 OGs computed/ 13396\n",
      "400 OGs computed/ 13396\n",
      "500 OGs computed/ 13396\n",
      "600 OGs computed/ 13396\n",
      "700 OGs computed/ 13396\n",
      "800 OGs computed/ 13396\n",
      "900 OGs computed/ 13396\n",
      "1000 OGs computed/ 13396\n",
      "1100 OGs computed/ 13396\n",
      "1200 OGs computed/ 13396\n",
      "1300 OGs computed/ 13396\n",
      "1400 OGs computed/ 13396\n",
      "1500 OGs computed/ 13396\n",
      "1600 OGs computed/ 13396\n",
      "1700 OGs computed/ 13396\n",
      "1800 OGs computed/ 13396\n",
      "1900 OGs computed/ 13396\n",
      "2000 OGs computed/ 13396\n",
      "2100 OGs computed/ 13396\n",
      "2200 OGs computed/ 13396\n",
      "2300 OGs computed/ 13396\n",
      "2400 OGs computed/ 13396\n",
      "2500 OGs computed/ 13396\n",
      "2600 OGs computed/ 13396\n",
      "2700 OGs computed/ 13396\n",
      "2800 OGs computed/ 13396\n",
      "2900 OGs computed/ 13396\n",
      "3000 OGs computed/ 13396\n",
      "3100 OGs computed/ 13396\n",
      "3200 OGs computed/ 13396\n",
      "3300 OGs computed/ 13396\n",
      "3400 OGs computed/ 13396\n",
      "3500 OGs computed/ 13396\n",
      "3600 OGs computed/ 13396\n",
      "3700 OGs computed/ 13396\n",
      "3800 OGs computed/ 13396\n",
      "3900 OGs computed/ 13396\n",
      "4000 OGs computed/ 13396\n",
      "4100 OGs computed/ 13396\n",
      "4200 OGs computed/ 13396\n",
      "4300 OGs computed/ 13396\n",
      "4400 OGs computed/ 13396\n",
      "4500 OGs computed/ 13396\n",
      "4600 OGs computed/ 13396\n",
      "4700 OGs computed/ 13396\n",
      "4800 OGs computed/ 13396\n",
      "4900 OGs computed/ 13396\n",
      "5000 OGs computed/ 13396\n",
      "5100 OGs computed/ 13396\n",
      "5200 OGs computed/ 13396\n",
      "5300 OGs computed/ 13396\n",
      "5400 OGs computed/ 13396\n",
      "5500 OGs computed/ 13396\n",
      "5600 OGs computed/ 13396\n",
      "5700 OGs computed/ 13396\n",
      "5800 OGs computed/ 13396\n",
      "5900 OGs computed/ 13396\n",
      "6000 OGs computed/ 13396\n",
      "6100 OGs computed/ 13396\n",
      "6200 OGs computed/ 13396\n",
      "6300 OGs computed/ 13396\n",
      "6400 OGs computed/ 13396\n",
      "6500 OGs computed/ 13396\n",
      "6600 OGs computed/ 13396\n",
      "6700 OGs computed/ 13396\n",
      "6800 OGs computed/ 13396\n",
      "6900 OGs computed/ 13396\n",
      "7000 OGs computed/ 13396\n",
      "7100 OGs computed/ 13396\n",
      "7200 OGs computed/ 13396\n",
      "7300 OGs computed/ 13396\n",
      "7400 OGs computed/ 13396\n",
      "7500 OGs computed/ 13396\n",
      "7600 OGs computed/ 13396\n",
      "7700 OGs computed/ 13396\n",
      "7800 OGs computed/ 13396\n",
      "7900 OGs computed/ 13396\n",
      "8000 OGs computed/ 13396\n",
      "8100 OGs computed/ 13396\n",
      "8200 OGs computed/ 13396\n",
      "8300 OGs computed/ 13396\n",
      "8400 OGs computed/ 13396\n",
      "8500 OGs computed/ 13396\n",
      "8600 OGs computed/ 13396\n",
      "8700 OGs computed/ 13396\n",
      "8800 OGs computed/ 13396\n",
      "8900 OGs computed/ 13396\n",
      "9000 OGs computed/ 13396\n",
      "9100 OGs computed/ 13396\n",
      "9200 OGs computed/ 13396\n",
      "9300 OGs computed/ 13396\n",
      "9400 OGs computed/ 13396\n",
      "9500 OGs computed/ 13396\n",
      "9600 OGs computed/ 13396\n",
      "9700 OGs computed/ 13396\n",
      "9800 OGs computed/ 13396\n",
      "9900 OGs computed/ 13396\n",
      "10000 OGs computed/ 13396\n",
      "10100 OGs computed/ 13396\n",
      "10200 OGs computed/ 13396\n",
      "10300 OGs computed/ 13396\n",
      "10400 OGs computed/ 13396\n",
      "10500 OGs computed/ 13396\n",
      "10600 OGs computed/ 13396\n",
      "10700 OGs computed/ 13396\n",
      "10800 OGs computed/ 13396\n",
      "10900 OGs computed/ 13396\n",
      "11000 OGs computed/ 13396\n",
      "11100 OGs computed/ 13396\n",
      "11200 OGs computed/ 13396\n",
      "11300 OGs computed/ 13396\n",
      "11400 OGs computed/ 13396\n",
      "11500 OGs computed/ 13396\n",
      "11600 OGs computed/ 13396\n",
      "11700 OGs computed/ 13396\n",
      "11800 OGs computed/ 13396\n",
      "11900 OGs computed/ 13396\n",
      "12000 OGs computed/ 13396\n",
      "12100 OGs computed/ 13396\n",
      "12200 OGs computed/ 13396\n",
      "12300 OGs computed/ 13396\n",
      "12400 OGs computed/ 13396\n",
      "12500 OGs computed/ 13396\n",
      "12600 OGs computed/ 13396\n",
      "12700 OGs computed/ 13396\n",
      "12800 OGs computed/ 13396\n",
      "12900 OGs computed/ 13396\n",
      "13000 OGs computed/ 13396\n",
      "13100 OGs computed/ 13396\n",
      "13200 OGs computed/ 13396\n",
      "13300 OGs computed/ 13396\n",
      "13400 OGs computed/ 13396\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# og_dict[keys|OG_id] -> values|dict[keys|species] -> values|list(gene_id)\n",
    "og_dict = {} \n",
    "omaid_2_ogid = {}\n",
    " \n",
    "with open(og_file) as f:\n",
    "    \n",
    "        content = f.readlines()\n",
    "        cpt = 0\n",
    "        \n",
    "        # for each og\n",
    "        for line in content:\n",
    "            cpt +=1 \n",
    "            if cpt % 100 == 0:\n",
    "                print(str(cpt) + \" OGs computed/ \" + str(len(content)-4))\n",
    "            # if line not comment\n",
    "            if line[0] != \"#\":\n",
    "                \n",
    "                #split by '\\t' to have each element in an list\n",
    "                line = line.rstrip('\\n')\n",
    "                spl =  line.split('\\t')\n",
    "                \n",
    "                # get og id and add it to og_dict\n",
    "                og_id = str(spl[0])\n",
    "                og_dict[og_id]={}\n",
    "                \n",
    "                # for each gene in the og\n",
    "                for gene in spl[1:]:\n",
    "                    \n",
    "                    # get its species\n",
    "                    sp = str(map_id.get_species_with_ext(gene[4:]))\n",
    "                    \n",
    "                    if sp != gene[:3]:\n",
    "                        sys.exit(\"Error of species mapping in the OG \" + og_id + \" for gene \" + gene)\n",
    "                    \n",
    "                    # get its oma id (since internal we are working with them)\n",
    "                    oma_id = str(map_id.get_omaid(str(gene[4:]), sp))\n",
    "                    \n",
    "                    # add the gene with the corresponding species key\n",
    "                    og_dict[og_id].setdefault(sp,[]).append(oma_id)\n",
    "                    \n",
    "                    omaid_2_ogid[str(sp) + str(oma_id)] = str(og_id)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "og_dict_plus = copy.deepcopy(og_dict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Get list species + PR files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_list_files(mypath):\n",
    "    onlyfiles = [ f for f in os.listdir(mypath) if isfile(join(mypath,f)) ]\n",
    "    return onlyfiles\n",
    "\n",
    "def get_list_species_from_standalone_folder(input_folder):\n",
    "    '''\n",
    "    return species name from the file names (species1-species2.ext) of the pairwise folder\n",
    "    :param input_folder:\n",
    "    :return:\n",
    "    '''\n",
    "    list_species = []\n",
    "    for file in get_list_files(input_folder):\n",
    "        file_name_no_ext = file.split(os.extsep, 1)[0]\n",
    "        array_name = file_name_no_ext.split(\"-\")\n",
    "        for species_name in array_name:\n",
    "            list_species.append(species_name)\n",
    "    return list(set(list_species))\n",
    "\n",
    "# Extract list of species from the PR folder\n",
    "list_species = get_list_species_from_standalone_folder(PR_folder)\n",
    "\n",
    "# Get the list of files\n",
    "PR_files = get_list_files(PR_folder)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Add many:many and 1:many link into OG plus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1/45\n",
      "2/45\n",
      "3/45\n",
      "4/45\n",
      "5/45\n",
      "6/45\n",
      "7/45\n",
      "8/45\n",
      "9/45\n",
      "10/45\n",
      "11/45\n",
      "12/45\n",
      "13/45\n",
      "14/45\n",
      "15/45\n",
      "16/45\n",
      "17/45\n",
      "18/45\n",
      "19/45\n",
      "20/45\n",
      "21/45\n",
      "22/45\n",
      "23/45\n",
      "24/45\n",
      "25/45\n",
      "26/45\n",
      "27/45\n",
      "28/45\n",
      "29/45\n",
      "30/45\n",
      "31/45\n",
      "32/45\n",
      "33/45\n",
      "34/45\n",
      "35/45\n",
      "36/45\n",
      "37/45\n",
      "38/45\n",
      "39/45\n",
      "40/45\n",
      "41/45\n",
      "42/45\n",
      "43/45\n",
      "44/45\n",
      "45/45\n"
     ]
    }
   ],
   "source": [
    "import collections\n",
    "\n",
    "\"\"\"UnionFind.py\n",
    "\n",
    "Union-find data structure. Based on Josiah Carlson's code,\n",
    "http://aspn.activestate.com/ASPN/Cookbook/Python/Recipe/215912\n",
    "with significant additional changes by D. Eppstein and\n",
    "Adrian Altenhoff.\n",
    "\"\"\"\n",
    "\n",
    "class UnionFind(object):\n",
    "    \"\"\"Union-find data structure.\n",
    "\n",
    "    Each unionFind instance X maintains a family of disjoint sets of\n",
    "    hashable objects, supporting the following two methods:\n",
    "\n",
    "    - X[item] returns a name for the set containing the given item.\n",
    "      Each set is named by an arbitrarily-chosen one of its members; as\n",
    "      long as the set remains unchanged it will keep the same name. If\n",
    "      the item is not yet part of a set in X, a new singleton set is\n",
    "      created for it.\n",
    "\n",
    "    - X.union(item1, item2, ...) merges the sets containing each item\n",
    "      into a single larger set.  If any item is not yet part of a set\n",
    "      in X, it is added to X as one of the members of the merged set.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, elements=None):\n",
    "        \"\"\"Create a new empty union-find structure.\"\"\"\n",
    "        self.weights = {}\n",
    "        self.parents = {}\n",
    "        if not elements is None:\n",
    "            for elem in iter(elements):\n",
    "                self.parents[elem] = elem\n",
    "                self.weights[elem] = 1\n",
    "\n",
    "    def __getitem__(self, obj):\n",
    "        return self.find(obj)\n",
    "\n",
    "    def find(self,obj):\n",
    "        \"\"\"Find and return the name of the set containing the obj.\"\"\"\n",
    "\n",
    "        # check for previously unknown obj. If unknown, add it \n",
    "        # as a new cluster\n",
    "        if obj not in self.parents:\n",
    "            self.parents[obj] = obj\n",
    "            self.weights[obj] = 1\n",
    "            return obj\n",
    "\n",
    "        # find path of objects leading to the root\n",
    "        path = [obj]\n",
    "        root = self.parents[obj]\n",
    "        while root != path[-1]:\n",
    "            path.append(root)\n",
    "            root = self.parents[root]\n",
    "\n",
    "        # compress the path and return\n",
    "        for ancestor in path:\n",
    "            self.parents[ancestor] = root\n",
    "        return root\n",
    "\n",
    "    def __iter__(self):\n",
    "        \"\"\"Iterate through all items ever found or unioned by this structure.\"\"\"\n",
    "        return iter(self.parents)\n",
    "\n",
    "    def union(self, *objects):\n",
    "        \"\"\"Find the sets containing the objects and merge them all.\"\"\"\n",
    "        roots = [self[x] for x in objects]\n",
    "        heaviest = max([(self.weights[r],r) for r in roots], key=lambda x:x[0])[1]\n",
    "        for r in roots:\n",
    "            if r != heaviest:\n",
    "                self.weights[heaviest] += self.weights[r]\n",
    "                self.parents[r] = heaviest\n",
    "\n",
    "    def get_components(self):\n",
    "        \"\"\"return a list of sets corresponding to the connected\n",
    "        components of the structure.\"\"\"\n",
    "        comp_dict = collections.defaultdict(set)\n",
    "        for elem in iter(self):\n",
    "            comp_dict[self[elem]].add(elem)\n",
    "        comp = list(comp_dict.values())\n",
    "        return comp\n",
    "    \n",
    "modified_og = []\n",
    "\n",
    "cpt = 0 \n",
    "for pr_file in PR_files:\n",
    "    \n",
    "    cpt += 1\n",
    "    print str(cpt) + \"/\" + str(len(PR_files))\n",
    "    \n",
    "    # get the name of the genomes pairs\n",
    "    file_name_no_ext = pr_file.split(os.extsep, 1)[0]\n",
    "    array_name = file_name_no_ext.split(\"-\")\n",
    "    \n",
    "    # get all pr relations\n",
    "    prs =  np.genfromtxt(PR_folder + pr_file, dtype=None, comments=\"#\", delimiter=\"\\t\", usecols=(0,1))\n",
    "    \n",
    "    # get all CC in the PR graph\n",
    "    cc_prs = UnionFind()\n",
    "    for pr in prs:\n",
    "        gene_l = array_name[0]+str(pr[0])\n",
    "        gene_r = array_name[1]+str(pr[1])\n",
    "        cc_prs.union(gene_l, gene_r)\n",
    "     \n",
    "    # Look in each CC if at least one of each genome is present in the same OG\n",
    "    for cc in cc_prs.get_components():\n",
    "        \n",
    "        if len(cc) > 2:\n",
    "            OG_sp = {}            \n",
    "            for gid in cc:\n",
    "                if gid in omaid_2_ogid.keys():\n",
    "                    OG_sp.setdefault(omaid_2_ogid[gid],[]).append(gid[:3])\n",
    "            for ogid, listsp in OG_sp.items():\n",
    "                if len(list(set(listsp))) == 2 :\n",
    "                    \n",
    "                    modified_og.append(ogid)\n",
    "                    for g2add in cc:\n",
    "                        if g2add[3:] not in og_dict_plus[ogid][g2add[:3]]:\n",
    "                            og_dict_plus[ogid][g2add[:3]].append(g2add[3:])\n",
    "    \n",
    "    modified_og = list(set(modified_og))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Write OG plus into file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('./OrthologousGroupsPlus.txt', 'w+')\n",
    "fl = open('./OrthologousGroupsPlusLongId.txt', 'w+')\n",
    "for ogi in og_dict_plus.keys():\n",
    "    f.write(ogi)\n",
    "    fl.write(ogi)\n",
    "    for spec in sorted(og_dict_plus[ogi].keys()):\n",
    "        for gid in og_dict_plus[ogi][spec]:\n",
    "            f.write(\"\\t\" + spec+gid )\n",
    "\n",
    "            fl.write(\"\\t\" + map_id.get_extid(gid,spec) )\n",
    "    f.write(\"\\n\")\n",
    "    fl.write(\"\\n\")\n",
    "f.close()\n",
    "fl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Write occupancy GO by species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 202,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (<ipython-input-202-4c1202d27378>, line 15)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"<ipython-input-202-4c1202d27378>\"\u001b[0;36m, line \u001b[0;32m15\u001b[0m\n\u001b[0;31m    fs.write\"\\t\" + (str(0) )\u001b[0m\n\u001b[0m               ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "fs = open('./OrthologousGroupsPlusStat.txt', 'w+')\n",
    "\n",
    "fs.write(\"#OGid\")\n",
    "for s in sorted(list_species):\n",
    "    fs.write(\"\\t\" + s) \n",
    "fs.write(\"\\n\")\n",
    "\n",
    "for ogi in og_dict_plus.keys():\n",
    "    fs.write(ogi)\n",
    "    \n",
    "    for s in sorted(list_species):\n",
    "        if s in og_dict_plus[ogi].keys():\n",
    "            fs.write( \"\\t\" + str(len(og_dict_plus[ogi][s])))\n",
    "        else:\n",
    "            fs.write(\"\\t\" + str(0) )\n",
    "    fs.write(\"\\n\")\n",
    "\n",
    "fs.close()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Write only modified OGplus and stat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "f = open('./OrthologousGroupsPlusOnlyModified.txt', 'w+')\n",
    "fl = open('./OrthologousGroupsPlusLongIdOnlyModified.txt', 'w+')\n",
    "for ogi in og_dict_plus.keys():\n",
    "    if ogi in modified_og:\n",
    "        f.write(ogi)\n",
    "        fl.write(ogi)\n",
    "        for spec in sorted(og_dict_plus[ogi].keys()):\n",
    "            for gid in og_dict_plus[ogi][spec]:\n",
    "                f.write(\"\\t\" + spec+gid )\n",
    "                fl.write(\"\\t\" + map_id.get_extid(gid,spec) )\n",
    "        f.write(\"\\n\")\n",
    "        fl.write(\"\\n\")\n",
    "f.close()\n",
    "fl.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###### Write occupancy of species in each OG only for modified OG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "fs = open('./OrthologousGroupsPlusStatOnlyModified.txt', 'w+')\n",
    "\n",
    "fs.write(\"#OGid\")\n",
    "for s in sorted(list_species):\n",
    "    fs.write(\"\\t\" + s) \n",
    "fs.write(\"\\n\")\n",
    "\n",
    "for ogi in og_dict_plus.keys():\n",
    "    if ogi in modified_og:\n",
    "        fs.write(ogi)\n",
    "\n",
    "        for s in sorted(list_species):\n",
    "            if s in og_dict_plus[ogi].keys():\n",
    "                fs.write( \"\\t\" + str(len(og_dict_plus[ogi][s])) )\n",
    "            else:\n",
    "                fs.write( \"\\t\" + str(0))\n",
    "        fs.write(\"\\n\")\n",
    "\n",
    "fs.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 192,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12345\n",
      "2345\n"
     ]
    }
   ],
   "source": [
    "x = \"tbe12345\"\n",
    "print x[3:]\n",
    "print x[4:]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
